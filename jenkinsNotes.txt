######## Jenkins ########

#### Jenkins Installation:
- Jenkins can be installed on various operating systems including Windows, macOS, and Linux distributions like Ubuntu, CentOS, and Red Hat.
- Make sure to have atleast 50 gb storage space for jenkins installation.
- using the below script resize the disk and logical volumes accordingly before installing jenkins.
        #!/bin/bash

        #resize disk from 20GB to 50GB
        growpart /dev/nvme0n1 4

        lvextend -L +10G /dev/mapper/RootVG-varVol # cause /var is where jenkins data will be stored
        lvextend -L +10G /dev/mapper/RootVG-rootVol # cause / is where jenkins will be installed
        lvextend -l +100%FREE /dev/mapper/RootVG-homeVol # cause /home is where user data will be stored

        xfs_growfs /
        xfs_growfs /var
        xfs_growfs /home

- For CentOS/RHEL based systems, follow the steps below to install Jenkins:
    -   sudo yum install -y wget # use wget or curl -o
    -   sudo wget --secure-protocol=TLSv1_2 -O /etc/yum.repos.d/jenkins.repo \
            https://pkg.jenkins.io/redhat-stable/jenkins.repo
            or
        curl -o /etc/yum.repos.d/jenkins.repo \
            https://pkg.jenkins.io/redhat-stable/jenkins.repo    
        rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key    
        sudo yum upgrade
        # Add required dependencies for the jenkins package
        sudo yum install fontconfig java-21-openjdk -y
        sudo yum install jenkins -y
        sudo systemctl daemon-reload
        sudo systemctl enable jenkins
        sudo systemctl start jenkins    

#### Unlocking Jenkins
- When you first access a new Jenkins controller, you are asked to unlock it using an automatically-generated password.

- Browse to http://localhost:8080 (or whichever port you configured for Jenkins when installing it) and wait until the Unlock Jenkins page appears.    

- From the Jenkins console log output, copy the automatically generated alphanumeric password (between the 2 sets of asterisks).

    Note:

    - The command: sudo cat /var/lib/jenkins/secrets/initialAdminPassword will print the password at console.

    - If you are running Jenkins in Docker using the official jenkins/jenkins image you can use sudo docker exec ${CONTAINER_ID or CONTAINER_NAME} cat /var/jenkins_home/secrets/initialAdminPassword to print the password in the console without having to open an interactive shell inside the container.



#### Installing Jenkins agents on remote nodes:
- To install jenkins agent on remote node, follow the steps below:
    - Login to jenkins master node UI.
    - Go to Manage Jenkins -> Manage Nodes and Clouds -> New Node.
    - Enter the node name, select "Permanent Agent" and click OK.
    - Fill in the required details like number of executors, remote root directory, labels, usage, launch method etc.
    - For launch method, select "Launch agents via SSH".
    - Enter the remote node's hostname or IP address, credentials (username and password or private key) and port (default is 22).
    - Click "Save" to create the node.
    - Jenkins will now attempt to connect to the remote node via SSH and install the agent software.
    - Once the agent is successfully installed, it will appear as "online" in the Jenkins nodes list and will be ready to accept jobs.

    Note: Make sure that the remote node has Java installed and is reachable from the Jenkins master node.
    - For our agent we  need to run the following script to install necessary packages and tools.
        #!/bin/bash

        #resize disk from 20GB to 50GB
        growpart /dev/nvme0n1 4

        lvextend -L +10G /dev/mapper/RootVG-varVol
        lvextend -L +10G /dev/mapper/RootVG-rootVol
        lvextend -l +100%FREE /dev/mapper/RootVG-homeVol

        xfs_growfs /
        xfs_growfs /var
        xfs_growfs /home

        # This is mandatory, nodejs installtion will break SSH if we dont update these packages
        dnf update -y openssl\* openssh\* -y
        yum install java-21-openjdk -y

        dnf module disable nodejs -y
        dnf module enable nodejs:20 -y
        dnf install nodejs -y

        # docker
        yum install -y yum-utils
        yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
        yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y
        systemctl start docker
        systemctl enable docker
        usermod -aG docker ec2-user

        # Terraform
        yum install -y yum-utils
        yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo
        yum -y install terraform

        # Trivy
        curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sudo sh -s -- -b /usr/local/bin v0.68.2

        # Maven
        dnf install maven -y

        # Python
        dnf install python3 gcc python3-devel -y

        # Helm
        curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-4
        chmod 700 get_helm.sh
        ./get_helm.sh

        # eksctl and kubectl
        curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.34.2/2025-11-13/bin/linux/amd64/kubectl
        chmod +x ./kubectl
        mkdir -p $HOME/bin && cp ./kubectl  /usr/local/bin && export PATH=$HOME/bin:$PATH

        ARCH=amd64
        PLATFORM=$(uname -s)_$ARCH
        curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"
        tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp && rm eksctl_$PLATFORM.tar.gz
        sudo install -m 0755 /tmp/eksctl /usr/local/bin && rm /tmp/eksctl



#### Writing a Jenkins file:
- A Jenkinsfile is a text file that contains the definition of a Jenkins Pipeline and is checked into source control.
- It is written using the Groovy programming language and defines the stages, steps, and other aspects of the pipeline.
- A simple Jenkinsfile example:
    ```
    pipeline {
        agent any   
        stages {
            stage('Build') {
                steps {
                    echo 'Building...'
                }
            }
            stage('Test') {
                steps {
                    echo 'Testing...'
                }
            }
            stage('Deploy') {
                steps {
                    echo 'Deploying...'
                }
            }
        }
    }

    ```
- It should be written in a file named "Jenkinsfile" and placed in the root directory of the source code repository.    

## Install plugins:
    - Git Plugin
    - stage view plugin
    - Pipeline Utility Steps
    - aws credentials
    - aws steps
    - sonarQube scanner



#### Documentation links:- https://www.jenkins.io/doc/book/pipeline/

## Pre build:
  prebuild steps are used to perform any setup or initialization tasks before the main build process begins. This can include tasks such as checking out source code from a version control system, setting up environment variables, installing dependencies, or preparing build artifacts. Pre-build steps help ensure that the build environment is properly configured and ready for the actual build process to take place.
    - Install "Pre Build Task" plugin in jenkins master.
    - In the job configuration, scroll down to the "Build Environment" section and check the "Pre Build Task" option.
    - Click on the "Add" button to add a new pre-build task.
    - In the "Command" field, enter the script or command that you want to run
        before the build starts. This can be a shell script, batch file, or any other command that is supported by your build environment.
## Build stage:
    The build stage in Jenkins is where the actual compilation, packaging, and building of the application takes place. This stage typically involves executing build scripts or commands that are specific to the programming language or framework being used. The build stage may include tasks such as compiling source code, running unit tests, generating build artifacts (e.g., JAR files, WAR files, Docker images), and performing code analysis or static code checks. The goal of the build stage is to produce a deployable artifact that can be used in subsequent stages of the CI/CD pipeline, such as testing and deployment.
        - In the job configuration, scroll down to the "Build" section.
        - Click on the "Add build step" button and select the appropriate build step for your project (e.g., "Execute shell", "Invoke Ant", "Invoke Gradle", etc.).
        - In the build step configuration, enter the commands or scripts that will perform the build process for your application. This may include compiling code, running tests, generating artifacts, etc.
        - Save the job configuration.
## Post build:
    Post-build steps in Jenkins are actions that are executed after the main build process has completed. These steps are typically used to perform tasks such as archiving build artifacts, sending notifications, publishing reports, or triggering downstream jobs. Post-build steps help ensure that the results of the build are properly managed        

Refer Jenkinsfile for more details.   



#### Declarative vs Scripted Pipeline:
- Declarative Pipeline is a more structured and opinionated way of defining Jenkins pipelines using a specific syntax. It provides a simpler and more readable syntax for defining pipelines, making it easier for users to
understand and maintain their pipeline code. Declarative Pipeline also includes built-in features for error handling, parallel execution, and stage-level configuration.
- Scripted Pipeline, on the other hand, is a more flexible and powerful way of defining Jenkins pipelines using Groovy code. It allows users to write custom logic and control flow in their pipeline
scripts, giving them more control over the pipeline execution. Scripted Pipeline is more suitable for complex pipelines that require advanced logic and customization.
- Declarative Pipeline is generally recommended for most users due to its simplicity and ease of use, while Scripted Pipeline is more suitable for advanced users who require more control and flexibility in their pipeline definitions. over time and that any necessary post-build actions are taken care of automatically.
    - In the job configuration, scroll down to the "Post-build Actions" section.
    - Click on the "Add post-build action" button and select the appropriate post-build action for your project (e.g., "Archive the artifacts", "Email Notification", "Publish JUnit test result report", etc.).
    - In the post-build action configuration, enter the necessary details and settings for the action you selected.
    - Save the job configuration.   

Example: 
    - Archive the artifacts: This post-build action allows you to specify files or directories to be archived after the build completes. You can use wildcards to specify multiple files or directories.
    - Email Notification: This post-build action allows you to send email notifications to specified recipients based on the build status (e.g., success, failure, unstable). You can customize the email subject and body.
    - Publish JUnit test result report: This post-build action allows you to publish JUnit test results generated during the build. You can specify the location of the test result XML files and configure options for displaying test results in Jenkins. and managed appropriately. This helps ensure that build artifacts are preserved

differences between Declarative and Scripted Pipeline in Jenkins:
| Feature                  | Declarative Pipeline                          | Scripted Pipeline                           |
|--------------------------|----------------------------------------------|---------------------------------------------|
| Syntax                   | Uses a specific, structured syntax           | Uses Groovy code with more flexibility         |
| Readability              | More readable and easier to understand       | Can be more complex and harder to read            |
| Error Handling           | Built-in error handling features             | Requires custom error handling logic              |
| Parallel Execution       | Built-in support for parallel stages         | Requires custom implementation for parallel execution      |
| Stage-level Configuration| Supports stage-level configuration options    | Requires custom logic for stage-level configuration        |
| Use Case                 | Suitable for most users and simpler pipelines | Suitable for advanced users and complex pipelines     |
| Maintenance               | Easier to maintain due to structured syntax   | Can be harder to maintain due to custom logic      |
| compilation                | No compilation step, interpreted at runtime  | Groovy code is compiled before execution         |
| syntax checking            | Limited syntax checking                       | Full Groovy syntax checking                    |  


Declarative is a Domain specific language on top of groovy from jenkins 2.0. 

Declarative pipeline is more structured and opinionated way of writing pipeline as code. and it is evaluated initially and then executed. It is a wrapper jenkins crated on top of groovu for strict evaluation of pipeline code.
Meanwhile scripted pipeline is more flexible and powerful way of writing pipeline as code. It is groovy based and it is compiled first and then executed.



## Environment section:
It is used to define environment variables that can be accessed throughout the pipeline. These variables can be used to store configuration values, credentials, or any other information that needs to be shared across different stages of the pipeline.
- In the Jenkinsfile, you can define environment variables using the "environment" block. For example:
    ```
    pipeline {
        agent any
        environment {
            MY_VAR = "some_value"
            ANOTHER_VAR = "another_value"
        }
        stages {
            stage('Example Stage') {
                steps {
                    echo "MY_VAR is ${env.MY_VAR}"
                    echo "ANOTHER_VAR is ${env.ANOTHER_VAR}"
                }
            }
        }
    }
    ```

    once defined they can be used in all the stages of the pipeline using the "env" object. or without env also.
- In this example, two environment variables (MY_VAR and ANOTHER_VAR) are defined in the "environment" block. These variables can then be accessed using the "env" object in the pipeline steps.
- You can also define environment variables at the job level in Jenkins, which will be available to all pipelines executed by that job. To do this, go to the job configuration page, scroll down to the "Build Environment" section, and check the "Inject environment variables" option.


## Options:
The "options" section in a Jenkins pipeline is used to define various options and settings that affect the behavior of the pipeline. These options can include things like timeout settings, retry strategies, build discarding policies, and more.
- In the Jenkinsfile, you can define options using the "options" block. For example:
    ```
    pipeline {
        agent any
        options {
            timeout(time: 30, unit: 'MINUTES')
            retry(3)
            buildDiscarder(logRotator(numToKeepStr: '10'))
        }
        stages {
            stage('Example Stage') {
                steps {
                    echo "This is an example stage"
                }
            }
        }
    }
    ``` 

    various options available in jenkins pipeline are:
    - timeout: Specifies a timeout for the entire pipeline or individual stages.
    - retry: Specifies the number of times to retry a failed stage or step.
    - buildDiscarder: Specifies a policy for discarding old builds to save disk space.
    - disableConcurrentBuilds: Prevents concurrent builds of the same pipeline.
    - skipDefaultCheckout: Skips the default SCM checkout step.
    - timestamps: Adds timestamps to the console output for better logging.
    - parallelAlwaysFailFast: Configures parallel stages to fail fast if any of them fail.
- In this example, three options are defined in the "options" block: a timeout of 30 minutes, a retry strategy of 3 attempts, and a build discarding policy that keeps the last 10 builds. These options will affect the behavior of the pipeline during its execution.

## Parameters:
The "parameters" section in a Jenkins pipeline is used to define input parameters that can be provided when triggering the pipeline. These parameters allow users to customize the behavior of the pipeline based on their specific needs.
- In the Jenkinsfile, you can define parameters using the "parameters" block. For example:
    ```
    pipeline {
        agent any
        parameters {
            string(name: 'MY_PARAM', defaultValue: 'default_value', description: 'This is a string parameter')
            booleanParam(name: 'ANOTHER_PARAM', defaultValue: true, description: 'This is a boolean parameter')
        }
        stages {
            stage('Example Stage') {
                steps {
                    echo "MY_PARAM is ${params.MY_PARAM}"
                    echo "ANOTHER_PARAM is ${params.ANOTHER_PARAM}"
                }
            }
        }
    }
    ``` 


 ## Trigger:
The "triggers" section in a Jenkins pipeline is used to define automated triggers that can start the pipeline based on specific events or conditions. These triggers allow you to automate the execution of your pipeline without manual intervention.
- In the Jenkinsfile, you can define triggers using the "triggers" block. For example:
    ```
    pipeline {
        agent any
        triggers {
            cron('H 2 * * 1-5') // Trigger the pipeline every weekday at 2 AM
            pollSCM('H/5 * * * *') // Poll the SCM for changes every 5 minutes
        }
        stages {
            stage('Example Stage') {
                steps {
                    echo "This is an example stage"
                }
            }
        }
    }
    ```
- In this example, two triggers are defined in the "triggers" block: a cron trigger that starts the pipeline every weekday at 2 AM, and a pollSCM trigger that checks the source code management (SCM) system for changes every 5 minutes. If any changes are detected, the pipeline will be triggered automatically.
- These triggers help automate the execution of the pipeline based on time-based schedules or changes in the source code repository.    ```
Refer documentation for more details: https://www.jenkins.io/doc/book/pipeline/syntax/#triggers

for git hub trigger, just add a webhook in the github repository settings pointing to your jenkins server webhook URL/github-webhook/


## Input:
The "input" step in a Jenkins pipeline is used to pause the pipeline execution and wait for user input before proceeding to the next stage or step. This is useful when you want to introduce manual approval or decision-making points in your pipeline.
- In the Jenkinsfile, you can use the "input" step within a stage or step. For example:
    ```
    pipeline {
        agent any
        stages {
            stage('Build') {
                steps {
                    echo "Building the application..."
                }
            }
            stage('Approval') {
                steps {
                    input message: 'Do you want to proceed to deployment?', ok: 'Yes, deploy'
                }
            }
            stage('Deploy') {
                steps {
                    echo "Deploying the application..."
                }
            }
        }
    }
    ```
- In this example, the pipeline has three stages: "Build", "Approval", and "Deploy". The "Approval" stage contains the "input" step, which pauses the pipeline and prompts
the user with a message asking for approval to proceed to deployment. The user can click the "Yes, deploy" button to continue the pipeline execution.
- The "input" step can also include additional parameters, such as a timeout period or a list of choices for the user to select from. This allows for more complex decision-making scenarios within the pipeline.
- Once the user provides the required input, the pipeline resumes execution and proceeds to the next stage or step. If the user does not provide input within the specified timeout period (if set),
the pipeline can be configured to either abort or continue based on the defined behavior.



#### Docker :
- We use ECR to store our docker images.
- Use the below commands to login to ECR, build and push the docker image to ECR.
- Create a repository in ECR with the name "repository_name" before pushing the image.
- Create a role or user with necessary permissions to push images to ECR. and store it in jenkins credentials with the name "aws-credentials"
  - In the jenkins pipeline, use the below commands in the build stage to push the docker image to ECR.
    - withAWS(credentials: 'aws-credentials', region: '<region>') { //commands here }
    - aws ecr get-login-password --region <region> | docker login --username AWS --password-stdin <aws_account_id>.dkr.ecr.<region>.amazonaws.com
    - docker build -t <repository_name> .
    - docker tag <repository_name>:latest <aws_account_id>.dkr.ecr.<region>.amazonaws.com/<repository_name>:latest
    - docker push <aws_account_id>.dkr.ecr.<region>.amazonaws.com/<repository_name>:latest



#### Code scanning with SonarQube:
- Install SonarQube server in a separate EC2 instance or use SonarQube cloud service.
- Install "SonarQube Scanner" plugin in jenkins master.
- in tools install a sonarQube scanner with a name "SonarQube-Scanner" 
- In the jenkins global configuration, add SonarQube server details and credentials.
- In the jenkins pipeline, use the below commands in the build stage to perform code scanning:
    - withSonarQubeEnv('SonarQube-Server-Name') {
        //commands here
      }
    - sonar-scanner \
      -Dsonar.projectKey=<project_key> \
      -Dsonar.sources=. \
      -Dsonar.host.url=<sonarqube_server_url> \
      -Dsonar.login=<sonarqube_token>   

